{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AI BiasBuster: Detecting and Mitigating Bias in Text**\n",
    "Welcome to the **AI BiasBuster** project! In this notebook, you will learn how to:\n",
    "1. Detect biases in text using a fine-tuned transformer model.\n",
    "2. Use the **WINOGENDER dataset** to train and evaluate your model.\n",
    "3. Save and test your trained model for real-world use.\n",
    "\n",
    "This notebook is beginner-friendly and assumes a basic understanding of Python and machine learning concepts. Let’s get started!\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "### **Why Detect Bias in AI?**\n",
    "AI systems are increasingly used in sensitive applications like hiring, healthcare, and content moderation. However, these systems can inherit biases present in the data they’re trained on. This project aims to detect such biases and mitigate them to create more fair and ethical AI systems.\n",
    "\n",
    "We’ll use the following tools:\n",
    "- **Hugging Face Transformers**: For fine-tuning the DistilBERT model.\n",
    "- **WINOGENDER Dataset**: A dataset designed to expose gender biases in language.\n",
    "- **PyTorch**: To run and train our machine learning model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Install and Import Libraries**\n",
    "Before we dive into the dataset or model, we need to ensure all the required libraries are installed.\n",
    "\n",
    "### **What Are We Installing?**\n",
    "- **Transformers**: For working with pre-trained models like DistilBERT.\n",
    "- **Datasets**: To load and preprocess our dataset.\n",
    "- **Torch**: For model training and inference.\n",
    "\n",
    "Let’s install and import these libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (4.48.0)\n",
      "Requirement already satisfied: datasets in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (3.0.1)\n",
      "Requirement already satisfied: torch in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (1.4.2)\n",
      "Requirement already satisfied: filelock in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from collections import Counter\n",
    "from datasets import DatasetDict\n",
    "from transformers import TrainingArguments\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available (optional but recommended)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Load and Explore the Dataset**\n",
    "### **Why the WINOGENDER Dataset?**\n",
    "The WINOGENDER dataset is specifically designed to reveal gender biases in language. It contains sentences where the gender of entities can be inferred, often leading to biased associations (e.g., \"nurse\" is stereotypically associated with females).\n",
    "\n",
    "### **What Will We Do in This Step?**\n",
    "1. Load the WINOGENDER dataset.\n",
    "2. Explore its structure and contents.\n",
    "3. Understand how it’s used for training.\n",
    "\n",
    "Let’s start by loading the dataset and inspecting its contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: dict_keys(['test'])\n",
      "New Dataset Splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentid', 'sentence', 'pronoun', 'occupation', 'participant', 'gender', 'target', 'label'],\n",
      "        num_rows: 576\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentid', 'sentence', 'pronoun', 'occupation', 'participant', 'gender', 'target', 'label'],\n",
      "        num_rows: 144\n",
      "    })\n",
      "})\n",
      "Number of training examples: 576\n",
      "Number of validation examples: 144\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"oskarvanderwal/winogender\", \"all\")\n",
    "\n",
    "# Check available splits\n",
    "print(\"Available splits:\", dataset.keys())\n",
    "\n",
    "# Split the 'test' data into 'train' and 'validation'\n",
    "data_split = dataset[\"test\"].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Create a DatasetDict with train and validation splits\n",
    "dataset = DatasetDict({\n",
    "    \"train\": data_split[\"train\"],\n",
    "    \"validation\": data_split[\"test\"]\n",
    "})\n",
    "\n",
    "# Verify the new splits\n",
    "print(\"New Dataset Splits:\", dataset)\n",
    "print(\"Number of training examples:\", len(dataset[\"train\"]))\n",
    "print(\"Number of validation examples:\", len(dataset[\"validation\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Labels in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Before Augmentation:\n",
      "Label 0: 286 examples\n",
      "Label 1: 290 examples\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of examples for each label\n",
    "label_counts = Counter(dataset[\"train\"][\"label\"])\n",
    "\n",
    "# Print the counts for each label\n",
    "print(\"Label Distribution Before Augmentation:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count} examples\")\n",
    "\n",
    "# Visualize the label distribution\n",
    "labels = list(label_counts.keys())\n",
    "counts = list(label_counts.values())\n",
    "\n",
    "plt.bar(labels, counts, color=['blue', 'orange'])\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Number of Examples\")\n",
    "plt.title(\"Label Distribution Before Augmentation\")\n",
    "plt.xticks(labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Does Data Augmentation Help in Predicting Biased Sentences?\n",
    "\n",
    "Data augmentation is a powerful technique for improving bias detection in machine learning models. While augmentation does not directly \"predict\" biases, it helps the model learn to recognize and generalize beyond stereotypical patterns.\n",
    "\n",
    "#### Why Use Augmentation for Bias Detection?\n",
    "1. **Focus on Context, Not Stereotypes**:\n",
    "   - Augmented examples challenge the model to pay attention to the meaning of the sentence, rather than sensitive attributes like gender or occupation.\n",
    "   - For example:\n",
    "     - Original: *\"The doctor said he would see the patient.\"*  \n",
    "     - Augmented: *\"The nurse said she would see the patient.\"*\n",
    "\n",
    "2. **Expose and Reduce Dataset Bias**:\n",
    "   - If the original dataset contains implicit biases (e.g., \"doctor\" is often paired with \"he\"), the model might perpetuate these patterns.\n",
    "   - Augmentation adds diversity to the dataset, exposing these biases and reducing their influence.\n",
    "\n",
    "3. **Balance Sensitive Attributes**:\n",
    "   - In real-world data, terms like \"doctor\" or \"nurse\" might not appear equally with \"he\" or \"she.\"\n",
    "   - Augmentation ensures the model sees all combinations, improving fairness and robustness.\n",
    "\n",
    "#### Practical Example\n",
    "Imagine the dataset contains only sentences like this:\n",
    "- *\"The doctor said he would see the patient.\" (label: 1)*\n",
    "\n",
    "Without augmentation, the model might incorrectly associate \"doctor\" with \"he\" as unbiased.\n",
    "\n",
    "With augmentation, we add a counterfactual:\n",
    "- *\"The nurse said she would see the patient.\" (label: 1)*\n",
    "\n",
    "Now, the model learns that \"doctor\" and \"nurse\" shouldn't affect the bias label.\n",
    "\n",
    "#### Key Benefits of Augmentation\n",
    "1. **Improved Generalization**:\n",
    "   - The model becomes better at handling unseen data by learning diverse patterns.\n",
    "2. **Uncovering Hidden Biases**:\n",
    "   - Augmentation reveals biases that might not be obvious in the original dataset.\n",
    "3. **Better Performance in Real-World Scenarios**:\n",
    "   - The model is exposed to a variety of sentence structures, reducing overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in augmented train dataset: 1152\n"
     ]
    }
   ],
   "source": [
    "# Augment the training data\n",
    "bias_replacements = {\"he\": \"she\", \"his\": \"her\", \"doctor\": \"nurse\"}\n",
    "\n",
    "def augment_sentence(sentence, replacements):\n",
    "    \"\"\"\n",
    "    Replaces specified words in a sentence to create counterfactual examples.\n",
    "    Args:\n",
    "        sentence: The original sentence.\n",
    "        replacements: A dictionary of words to replace and their replacements.\n",
    "    Returns:\n",
    "        Augmented sentence with specified replacements.\n",
    "    \"\"\"\n",
    "    for word, replacement in replacements.items():\n",
    "        sentence = sentence.replace(word, replacement)\n",
    "    return sentence\n",
    "\n",
    "def augment_dataset(dataset, replacements):\n",
    "    \"\"\"\n",
    "    Augments a dataset by adding counterfactual examples.\n",
    "    Args:\n",
    "        dataset: The original dataset (Hugging Face Dataset object).\n",
    "        replacements: A dictionary of words to replace and their replacements.\n",
    "    Returns:\n",
    "        Augmented dataset containing original and counterfactual examples.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    for example in dataset:\n",
    "        # Add original sentence\n",
    "        augmented_data.append(example)\n",
    "\n",
    "        # Add augmented sentence\n",
    "        augmented_sentence = augment_sentence(example[\"sentence\"], replacements)\n",
    "        augmented_example = {\n",
    "            \"sentence\": augmented_sentence,\n",
    "            \"label\": example[\"label\"]\n",
    "        }\n",
    "        augmented_data.append(augmented_example)\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Apply augmentation to the train split\n",
    "train_data = dataset[\"train\"]\n",
    "augmented_train_data = augment_dataset(train_data, bias_replacements)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "augmented_train_dataset = Dataset.from_dict({\n",
    "    \"sentence\": [example[\"sentence\"] for example in augmented_train_data],\n",
    "    \"label\": [example[\"label\"] for example in augmented_train_data]\n",
    "})\n",
    "\n",
    "# Replace the original train split with the augmented dataset\n",
    "dataset[\"train\"] = augmented_train_dataset\n",
    "print(\"Number of examples in augmented train dataset:\", len(dataset[\"train\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: Counter({1: 580, 0: 572})\n"
     ]
    }
   ],
   "source": [
    "label_counts = Counter(dataset[\"train\"][\"label\"])\n",
    "print(\"Label distribution:\", label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to compare\n",
    "\n",
    "model_names = {\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"MiniLM\": \"microsoft/MiniLM-L12-H384-uncased\",\n",
    "    \"TinyBERT\": \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why Do We Need Preprocessing?**\n",
    "Before we can train a model, we need to convert raw text into a format that the model understands. This involves **tokenization**, where sentences are broken into smaller components (like words or subwords) and mapped to numeric IDs.\n",
    "\n",
    "### **What Will We Do in This Step?**\n",
    "1. Load a tokenizer from the Hugging Face library.\n",
    "2. Preprocess the sentences in the dataset.\n",
    "\n",
    "Now, let’s tokenize the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the Data**\n",
    "# To train the model, we need to tokenize the text so it can be processed by models.\n",
    "\n",
    "# Function to tokenize the dataset\n",
    "def tokenize_dataset(dataset, model_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "    tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "    print(\"Tokenization complete!\")\n",
    "    return tokenized_dataset, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: Fine-Tune the Model**\n",
    "### **What Is Fine-Tuning?**\n",
    "Fine-tuning involves taking a pre-trained model (like DistilBERT) and training it on a specific task (bias detection). This allows the model to adapt to your dataset while leveraging the knowledge it has already learned from vast amounts of text.\n",
    "\n",
    "### **What Will We Do in This Step?**\n",
    "1. Load the pre-trained DistilBERT model.\n",
    "2. Define training parameters.\n",
    "3. Fine-tune the model using the tokenized dataset.\n",
    "\n",
    "Let’s begin!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (4.48.0)\n",
      "Requirement already satisfied: accelerate in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (1.2.1)\n",
      "Requirement already satisfied: filelock in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/Senjuti/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, model_path, tokenized_dataset):\n",
    "    \"\"\"\n",
    "    Train and evaluate a single model.\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2).to(device)\n",
    "\n",
    "    # Define metrics\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = logits.argmax(axis=-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=2,  # Accumulate gradients to simulate a larger batch\n",
    "        save_steps=1000,\n",
    "        logging_dir=f\"./logs_{model_name}\",\n",
    "        logging_steps=100,\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Starting Training for {model_name}...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"Evaluating the model {model_name}...\")\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"Evaluation Metrics for {model_name}:\", metrics)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 5: Save the Model**\n",
    "\n",
    "After training the model, it’s important to save it along with the tokenizer. This ensures that the trained model can be reused for testing, inference, or deployment without needing to retrain it.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Save the Model?**\n",
    "\n",
    "- **Reuse**: The saved model can be loaded anytime for predictions or further fine-tuning.  \n",
    "- **Portability**: You can transfer the model to another environment or share it with others.  \n",
    "- **Deployment**: Saved models are essential for deploying AI solutions in production systems.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Save the Model?**\n",
    "\n",
    "We will:\n",
    "1. Save the fine-tuned model weights.  \n",
    "2. Save the tokenizer configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_tokenizer(model, tokenizer, model_name):\n",
    "    \"\"\"\n",
    "    Saves the model and tokenizer to a specified directory.\n",
    "    Args:\n",
    "        model: The trained model to save.\n",
    "        tokenizer: The tokenizer to save.\n",
    "        model_name: The name of the model (used for directory naming).\n",
    "    \"\"\"\n",
    "    save_path = f\"./{model_name}_bias-mitigation-model\"\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    print(f\"Model and tokenizer for {model_name} saved successfully at {save_path}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6: Test the Model**\n",
    "\n",
    "Now that the model is fine-tuned, let’s test it with an example sentence to see how well it performs. This step will load the trained model and tokenizer for inference and run it on a sample input.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Are We Testing the Model?**\n",
    "\n",
    "After training, it’s important to check if the model can make meaningful predictions. By testing it on a specific sentence, we can verify if the model understands and detects potential bias.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Will We Do?**\n",
    "\n",
    "1. Load the fine-tuned model and tokenizer.\n",
    "2. Prepare a sample input sentence.\n",
    "3. Run inference and analyze the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, model_path, tokenizer_path, test_sentences):\n",
    "    \"\"\"\n",
    "    Test a trained model on example sentences.\n",
    "    \"\"\"\n",
    "    # Load the trained model and tokenizer\n",
    "    classifier = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer_path)\n",
    "\n",
    "    print(f\"Testing the model {model_name}...\")\n",
    "    for sentence in test_sentences:\n",
    "        result = classifier(sentence)\n",
    "        print(f\"Input: {sentence}\")\n",
    "        print(f\"Prediction: {result}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: DistilBERT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff7120df065440a9759dd4bbb628d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Senjuti/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training for DistilBERT...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/216 00:00 < 01:38, 2.16 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"The nurse said the doctor would see the patient soon.\",\n",
    "    \"The CEO welcomed the new male engineer.\",\n",
    "    \"She is a great leader and makes tough decisions.\",\n",
    "    \"The teacher said that he would grade the exams by tomorrow.\",\n",
    "    \"The firefighter saved the child from the burning building.\",\n",
    "    \"She is a nurse, and he is a doctor.\",\n",
    "    \"The programmer quickly fixed the critical bug.\"\n",
    "]\n",
    "\n",
    "# Loop through models\n",
    "for model_name, model_path in model_names.items():\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "    \n",
    "    # Tokenize the dataset\n",
    "    tokenized_dataset, tokenizer = tokenize_dataset(dataset, model_path)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model = train_and_evaluate_model(model_name, model_path, tokenized_dataset)\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    model.save_pretrained(f\"./{model_name}_bias-mitigation-model\")\n",
    "    tokenizer.save_pretrained(f\"./{model_name}_bias-mitigation-model\")\n",
    "    print(f\"Model and tokenizer for {model_name} saved successfully!\")\n",
    "\n",
    "    # Test the model\n",
    "    test_model(model_name, f\"./{model_name}_bias-mitigation-model\", f\"./{model_name}_bias-mitigation-model\", test_sentences)\n",
    "\n",
    "    print(f\"Completed processing for {model_name}.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **Output Explanation**\n",
    "\n",
    "When you test the fine-tuned model, it will generate an output for each input sentence. The output provides two key pieces of information:\n",
    "\n",
    "### **1. `label`**\n",
    "- This field indicates whether bias was detected in the input sentence.\n",
    "- Common values:\n",
    "  - **`LABEL_0`**: No bias detected.\n",
    "  - **`LABEL_1`**: Bias detected.\n",
    "- These labels correspond to the two classes the model was trained to predict. You can customize these labels during fine-tuning (e.g., replacing `LABEL_0` with \"No Bias\" and `LABEL_1` with \"Bias Detected\").\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `score`**\n",
    "- This field represents the model's confidence in its prediction.\n",
    "- The value is a probability ranging between **0** and **1**, where:\n",
    "  - **Close to 1**: The model is very confident in its prediction.\n",
    "  - **Close to 0**: The model is uncertain about its prediction.\n",
    "- Example:\n",
    "  - If the `score` is `0.85` for `LABEL_1`, the model is 85% confident that bias is present in the sentence.\n",
    "\n",
    "---\n",
    "\n",
    "### **Sample Output**\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"label\": \"LABEL_1\",\n",
    "        \"score\": 0.85\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "#### **Interpretation**:\n",
    "- **`label`**: `\"LABEL_1\"` means the model detected bias in the input sentence.\n",
    "- **`score`**: `0.85` means the model is 85% confident about this prediction.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
